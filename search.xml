<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[高性能MsSQL]]></title>
    <url>%2F%E9%AB%98%E6%80%A7%E8%83%BDMySQL(%E4%B8%80).html</url>
    <content type="text"><![CDATA[一、逻辑架构1. 连接管理与安全性第一层:大多基于网络客户端/服务器的工具或者服务都有类似的架构，比如连接处理，授权认证，安全等等。第二层：mysql核心功能都在这一层，包括查询解析、分析、优化、缓存以及所有的内置函数。所有的跨存储引擎功能都在这一层实现，比如触发器、存储过程、视图等。第三层：包含存储引擎，负责mysql中的数据的存储和提取。不会解析sql，不同存储引擎也不会相互通信，只是简单的响应上层服务器的请求。2.优化与执行每个客户端连接都会在服务器进程中都有一个线程，这个连接的查询只会在这个单独的线程中执行，服务器会缓存线程，不需要新建和销毁。第一步:当客户端连接到服务器时，服务器对其进行认证，基于用户名，密码，原始主机信息，连接成功后，会继续验证该客户端是否有执行某个特定查询的权限。第二步：认证通过后，mysql会解析查询，并创建内部数据结构，对其进行优化，包括重写查询，决定表的读取顺序，以及选择合适的索引。用户可以通过关键字(hint)提示优化器，也可以通过explain请求服务器解释优化过程。第三步：对于select查询，在解析查询之前，服务器会先检查查询缓存，如果能够在其中找到对应的查询，服务器就不必再执行查询解析、优化和执行的整个过程，而是直接返回查询缓存中的结果集。二、并发控制1.读写锁在处理并发读或者写的时候，可以通过实现一个由两种类型的锁组成的锁系统来解决问题。通常被称为共享锁和排他锁，也叫读锁和写锁。读锁(共享锁)：读锁是共享的，或者说是相互不阻塞的。多个客户在同一时刻可以同时读取同一个资源。而互不干扰。写锁(排它锁)：一个写锁会阻塞其他的写锁和读锁，这个处于安全策略的考虑，只有这样，才能确保在给定的时间里，只有一个用户能执行写入，并防止其他用户读取正在写入的统一资源。在实际数据库系统中，锁时时刻刻都在发生，当某个用户正在修改一部分数据时，mysql会通过锁定防止其他用户读取统一数据。2.锁粒度提高共享资源并发性的方式就是让锁定对象更有选择性。尽量只锁定需要修改的部分数据，而不是所有的资源。而加锁也需要消耗资源。锁的各种操作，包括获得锁、检查锁是否已经被解除、释放锁都会增加系统开销。所谓所策略，就是在锁的开销和数据的安全性之间寻找平衡，一般都是在表上施加行级锁。表锁：最基本的锁策略，并且是开销最小的策略，它会锁住整张表。一个用户在对表进行写操作(插入、删除、更新等)前，需要先获得写锁，这会阻塞其他用户对该表的所有读写操作。只有没有写锁时，其他读取用户才能获取读锁，读锁之间是不相互阻塞的。特定场景中，表锁也可能有良好的性能。例如，READ LOCAL表锁支持某些类型的并发操作。另外，写锁也比读锁有更高的优先级，因此一个写锁请求可能会被插入到读锁队列前面，反之不不能。行级锁：可以最大程度地支持并发处理(同时也带来了最大的锁开销)。众所周知，在InnoDB和XtraDB，以及其他的一些存储引擎中实现了行级锁。行级锁只在存储引擎层实现，而mysql服务器层没有实现。三、事务事务就是一组原子性的sql操作，或者说一个独立的工作单元。如果数据库引擎能够成功的对数据库应用该组操作的全部语句，那么就执行该组操作，如果其他有任何一条语句因为崩溃或者其他原因无法执行，那么所有语句都不会执行。一句话总结：事务内的语句，要么全部执行成功，要么全部执行失败.1.ACID:原子性(atomicity):一个事务必须被视为一个不可分割的最小工作单元，不可能只执行其中的一部分，这就是事务的原子性。一致性(consistency)：数据库总是从一个一致性的状态转换到另外一个一致性的状态，事务中的操作要么全部执行成功，要么全部失败回滚。隔离性(isolation)一个事务所做的修改在最终提交之前，对其他事务是不可见的。持久性(durability)一旦事务提交，对其所做的修改就会永久保存到数据库中。此时即使系统崩溃，修改的数据也不会丢失。2.隔离级别：READ UNCOMMITTED(未提交读)：在未提交读级别，事务中的修改，即使没有提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也称为脏读。这个级别会导致很多问题，从性能上来说，不会比其他级别好太多，缺缺乏其他级别的很多好处，一般很少使用。READ COMMITTED(提交读/不可重复读)解决了脏读的问题。大多数数据默认的隔离级别，mysql不是。简单定义：一个事务开始时，只能“看见”已经提交的事务所做的修改。换句话说，一个事务从开始知道提交之前，所做的任何修改对其他事务都不可见的。两次执行同样的查询，可能会得到不一样的结果，产生了不可重复读的问题。REPEATABLE READ(可重复读)：解决了脏读和不可重复读的问题。mysql的默认隔离级别，该级别保证了再同一事务中多次读取同样记录的结果是一致的。但是无法解决幻读的问题。所谓幻读，指的是当某个事务在读取某个范围内的记录时，另一个事务又会在该范围内插入新的记录，当之前的事务再次读取该范围内的技术时，会产生幻行。InnoDB和XtraDB存储引擎通过多版本并发控制，解决幻读问题。SERIALIZABLE(可串行化)：最高的隔离级别，通过强制事务串行执行，避免了前面说的幻读的问题，会在读取的每一行都加上所，所以可能导致大量的超时和锁争用的问题。实际中很少用到，只有在非常需要确保数据的一致性而且没有并发的情况下，才考虑采用该级别。总结：3.死锁两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。当多高事务试图以不同的顺序锁定资源时，就可能产生死锁。多个1事务同事锁定同一个资源时，也会产生死锁。如何解决死锁？数据库系统实现了各种死锁检测和死锁超时机制。越复杂的系统，比如InnoDB存储引擎，越能检测出死锁的循环依赖，并立即返回一个错误。这种解决方法很有效。另一种解决方式，就是当查询的时候达到锁等待超时的设定后放弃锁请求，这种方法不太好。InnoDB目前处理死锁的方法是，将持有最少行级排它锁的事务进行回滚。死锁发生后，只有部分或者完全回滚其中的一个事务，才能打破死锁。大多数情况下只需要重新执行因死锁回滚的1事务即可。4.事务日志提高事务效率，使用时，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不需要每次都将修改的数据本社持久到磁盘。事务日志采用追加的方式，因此写日志的操作是在磁盘上一小块区域内的顺序I/O，事务日志持久以后，内存中被修改的数据在后台可以慢慢地刷回到磁盘，通常称为预写式日志，修改数据需要写两次磁盘。如果日志持久化但是数据没有写回磁盘时，系统奔溃，存储引擎在重启后能够自动恢复这部分被修改的数据。5.mysql中的事务提供两种事务型的存储引擎：InnoDB和NDB Cluster。默认采用自动提交模式，如果不是显式地开始一个事务，则每个查询都被当做一个事务执行提交操作。InnoDB采用的是两阶段锁定协议。在事务执行过程中，随时都可以执行锁定，锁只有在执行COMMIT或者ROLLBACK的时候才会被释放，并且所有的锁是在同一时刻被释放。四、多版本并发控制(MVCC)以InnoDB为主，是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的过期时间(或删除时间)。当然存储的不是实际的时间值，而是系统版本号。每开始一个新的事务，系统版本号会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询道德每行记录的版本号进行比较。下面看一下，在可重复读的级别下，MVCC具体操作。1.SELECTInnoDB会根据以下两个条件检查每行记录：a.InnoDB只查找版本早于当前事务版本的数据行(也就是行的系统版本号小于或者等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过得。b.行的删除版本要么未定义，要么大于当前事务版本。这样可以确保事务读到的行，在失误开始之前未被删除。只有符合符合上述两个条件的记录，才能返回作为查询结果。2.INSERTInnoDB为新插入的每一行保存当前系统版本号作为行版本号。3.DELETEInnoDB为删除的的每一行保存当前系统版本号作为行删除标识。4.UPDATEInnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。、优缺点：保存这两个额外的系统版本号，使大多数读操作都可以不用加锁，操作简单，性能很好，能够保证只会读到符合标准的行。不足在于每个记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作。mysql只在可重复读和提交读两个隔离机制下工作。存储引擎1.InnoDBmysql默认的事务型引擎，数据存储在表空间，它是InnoDB管理的黑盒子，由一系列的数据文件组成，可以将每个表的数据和索引存放在单独文件中。采用MVCC来支持高并发，并且实现1李四光标准的隔离级别，默认是可重复读，并且可以通过间隙锁策略防止幻读的出现。间隙锁使得InooDB不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，防止幻影行的插入。表基于聚簇索引建立，对主键查询有很高的性能，不过它的耳机索引中必须包含主键列。所以主键列很大的话，其他索引都会很大。如果表索引较多，主键应当尽可能的小。内如做了很多优化，包括从磁盘读取数据时采用的可预测性玉都，能够自动在内存中创建hash索引以加速读操作的自适应哈希索引，以及能够加速插入操作的插入缓冲区。2.MyISAMmysql5.1版本以前的默认索引，提供大量特性，包括全文索引、压缩、空间函数，但是不支持事务和行级锁，崩溃后无法安全修复对于只读的数据，或者表比较小、可以忍受修复操作，可以使用MyISAM。特性：加锁与并发针对整张表加锁，而不是针对行，读取时会读到所有表加共享锁，写入时则对表加排他。但是在标有读取查询的同时，也可以往表里插入新的数据。修复可以收工或者自动执行检查和修复操作，执行表的修复可能导致一些数据丢失，而且修复操作非常慢，可以通过CHECK TABLE mytalbe检查表的错误，如果有错误，可以通过执行REPAIR TABLE mytalbe 进行修复。索引特性既是是BLOB和TEXT等长字段，也可以基于前500个字符创建索引，MyISAM也支持全文索引，这是一种基于分词创建的索引，可以支持复杂的查询。延迟更新索引创建表时如果指定了DELAY_KEY_WRITE选项，在每次修改执行完成时，不会立刻将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引2块写入磁盘，极大的提升写入性能，但是数据库或系统崩溃会造成索引损坏。3.mysql内建的其他存储引擎Archive引擎只支持INSERT和SELECT操作。Blackhole引擎，没有实现任何的存储机制，它会丢弃索引插入的数据，不做任何保存。CSV引擎可以将普通的CSV文件作为mysql的表来处理，但这种表不支持索引。Federated引擎方位其他mysql服务器的一个代理，它会创建一个到远程mysql服务器的客户端连接，并将查询传输到远程服务器执行，然后提取或者发送需要的数据。Memory引擎如果需要快速地访问数据，并且这些数据不会被修改，重启后丢失也没有关系，则使用Memory表是非常有用的。至少比MyISAM表快一个数量级，因为所有数据数据都保存在内存中，不需要进行磁盘I/O。Merge引擎是MyLSAM引擎的变种，由多个MyISAM表合并而来的虚拟表，引入分区后，该引擎已经被放弃。NDB集群引擎mysql服务器，NDB集群存储引擎，以及分布式的、share-nothing的、容灾的、高可用的NDB数据库的组合，被称为msql集群。4.选择合适的存储引擎大多数情况下，InooDB都是正确的选择，所以在mysql5.5版本后将InnoDB作为默认的存储引擎了，。简单归纳一句话：”除非需要用到某些InnoDB不具备的特性，并没有其他办法代替，否则都应该优先选择InnoDB”。例如用到全文索引，建议优先考虑InnoDB加上Sphinx的组合，而不是支持全文索引的MyISAM。5.转换表的引擎ALTER TABLE将表从一个引擎修改为另一个引擎最简单的方法就是使用ALTER TABLE语句1mysql&gt; ALTER TABLE mytable ENGINE = InnoDB;需要执行很长时间，原表会加上读锁，会失去和原引擎先关的所有特性。导出与导入使用mysqldump工具将数据到处到文件，然后修改文件中CREATE TABLE语句的存储引擎选择，注意同时修改表名。同时要注意mysqldump默认会自动在CREATE TABLE语句前面加上DROP TABLEy语句，不注意这一点可能会导致数据丢失。创建与查询综合了第一种和第二张方法，不需要导出整个表数据，而是先创建一个新的存储引擎的表，然后利用INSERT—-SELECT语法来导数据：123mysql&gt;CREATE TABLE innodb_table LIKE myisam_table;mysql&gt;ALTER TABLE innodb_table=InnoDB;mysql&gt;INSERT INTO innodb_table SELECT * FROM myisam_table;数据量很大，可以考虑做分批处理，针对每一段时间只需事务提交操作，以避免大事务产生过多的uudo。假设有主键字段id，重复运行以下语句(最小值x和最大值y)将数据导入新表：123mysql&gt; START TRANSACTION;mysql&gt; INSERT INTO innodb_table SELECT * FROM myisam_table-&gt; WHERE id BETWEEN x AND y;mysql&gt; COMMIT;这样操作完成以后，新表是原表的一个全量复制，原表还在，如果需要可以删除原表。如果有必要，可以在执行的过程中对原表加锁，以确保新表和原表的数据一致。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML类图]]></title>
    <url>%2FUML%E7%B1%BB%E5%9B%BE.html</url>
    <content type="text"><![CDATA[一、什么是UML图？UML（Unified Modeling Language）是一种统一建模语言，为面向对象开发系统的产品进行说明、可视化、和编制文档的一种标准语言。UML图分为用例视图、设计视图、进程视图、实现视图和拓扑视图，又可以静动分为静态视图和动态视图。静态图分为：用例图，类图，对象图，包图，构件图，部署图。动态图分为：状态图，活动图，协作图，序列图。二、UML类图用户根据用例图抽象成类，描述类的内部结构和类与类之间的关系，是一种静态结构图。 在UML类图中，常见的有以下几种关系: 泛化（Generalization）, 实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)。各种关系的强弱顺序： 泛化 = 实现 &gt; 组合 &gt; 聚合 &gt; 关联 &gt; 依赖泛化：是一种继承关系，指定了子类如何继承父类的所有特征和行为。实现+空心三角箭头表示。实现：是一种类与接口的关系，表示类是接口所有特征和行为的实现。虚线+空心三角箭头表示。关联：是一种拥有关系，它使一个类知道另一个类的属性和方法。可以是单向也可以是双向。双向关联可以有两个箭头或者没有箭头，单向的关联有一个箭头。聚合：是整体与部分的关系，且部分可以离开整体而单独存在。实线+空心菱形表示组合：是整体与部分的存在，但是部分不能离开整体而单独存在。实现+实心菱形表示依赖：是一种使用的关系，一个类的实现需要另一个类的协助，尽量避免双向协助。带箭头的虚线，指向被使用者三、示例图]]></content>
      <categories>
        <category>随记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一句话设计模式]]></title>
    <url>%2F%E4%B8%80%E5%8F%A5%E8%AF%9D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html</url>
    <content type="text"><![CDATA[创造类单例模式：确保一个类只有一个实例，而且自行实例化并像整个系统提供这个实例。私有化构造方法，提供公共方法获得实例。工厂方法模式：定义一个用于创建对象的接口，让子类决定实例化哪个类，工厂方法使一个类的实例化延迟到了子类。抽象工厂模式：为创建一组相关的或者相互依赖的的对象提供一个接口，而无需指定他们的具体类。建造者模式：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示原型模式：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。实现Cloneable接口，重写clone方法。迭代器模式：提供一个方法访问一个容器对象中的各个元素，而又不需暴露该对象的内部细节。Java中已经默认实现，使用foreach即可。行为类命令模式：把一个请求或者操作封装在命令对象中，命令模式允许系统使用不同的请求把客户端参数化，对请求排队或者记录请求日志，可以提供命令的撤销和回复功能。解释器模式：给定一种语言，定义它的文法的一种表示，并定义一个解释器，该解释器使用该表示来解释语言中的句子。责任链模式：使多个对象都有机会处理请求，从而避免了请求的发送者和接受者1之间的解耦关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有对象处理它为止。观察者模式：定义对象间一种一对多的依赖关系，使得每当一个对象改变状态，则所有依赖于它的对象都会得到通知被自动更新。中介者模式：用一个中介对象封装一系列对象的交互，中介者使各对象不需要显示地相互作用，从而使其耦合松散，而且可以独立的改变它们之间的交互。备忘录模式：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样以后就可以将该对象恢复到原先保存的状态。状态模式：当一个对象内在状态改变时允许其改变行为，这个对象看起来像是改变了其类。策略模式：定义一组算法，将每个算法都封装起来，并且可以使他们之间可以相互转换。模板方法模式：定义一个操作中的算法骨架，而将一些步骤延伸到子类，使得子类可以不改变一个算法结构即可重定义该算法的某些特定步骤。访问者模式：封装一些作用于某种数据结构中各元素的操作，它可以在不改变数据结构的前提下定于作用于这些元素的新操作。结构类适配器模式：将一个类的接口变换成客户端所期待的另一个接口，从而使本因接口不必配而无法工作的两个类能够在一起工作。组合模式：将对象组合成树形结构以表示”部分-整体”的层次结构，使得用户对单个对象和组合对象的使用具有一致性。代理模式；为其他对象提供一种代理以控制这个对象的访问。桥梁模式：将抽象和实现解耦，使得两者可以独立的变化。装饰模式：动态的给一个对象添加一些额外的职责，就增加功能来说，它相比生成子类更为灵活门面模式：要求一个子系统的外部与内部得同学都必须通过一个统一的对象进行，门面模式提供一个搞层次的接口，使得子系统更易于使用。享元模式：使用共享对象可以有效的支持大量的细粒度的对象。代码相关链接：《大话设计模式》 《设计模式之禅》]]></content>
      <categories>
        <category>随记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Resful相关]]></title>
    <url>%2FResful%E7%9B%B8%E5%85%B3.html</url>
    <content type="text"><![CDATA[一、什么是Resful？RESTful是一种软件架构风格、设计风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。二、常用方法：1234GET /blog/getArticles --&gt; GET /blog/Articles 获取所有文章GET /blog/addArticles --&gt; POST /blog/Articles 添加一篇文章GET /blog/editArticles --&gt; PUT /blog/Articles 修改一篇文章 GET /rest/api/deleteArticles?id=1 --&gt; DELETE /blog/Articles/1 删除一篇文章三、一句话总结！URL定位资源,HTTP动词描述操作。四、如何在resful传入多个参数？1@PutMapping(value = &quot;wx/createCustomer/&#123;number&#125;/&#123;nickName&#125;.do&quot;)五、@PathVariable 和 @RequestParam区别：@PathVariable用来绑定url模板变量值，获取url请求中的动态参数12345678910@RequestMapping(&quot;/zyh/&#123;type&#125;&quot;) public String zyh(@PathVariable(value = &quot;type&quot;) int type) throws UnsupportedEncodingException &#123; String url = &quot;http://wx.diyfintech.com/zyhMain/&quot; + type; if (type != 1 &amp;&amp; type != 2) &#123; throw new IllegalArgumentException(&quot;参数错误&quot;); &#125; String encodeUrl = URLEncoder.encode(url, &quot;utf-8&quot;); String redirectUrl = MessageFormat.format(OAUTH_URL, WxConfig.zyhAppId, encodeUrl, &quot;snsapi_userinfo&quot;, UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;)); return &quot;redirect:&quot; + redirectUrl; &#125;@RequestParam控制层用来获取参数12345678910111213141516171819@Controller@RequestMapping(&quot;/wx&quot;)public class WxController &#123; @Autowired private WxService wxService; private static final Log log= LogFactory.getLog(WxController.class); @RequestMapping(value = &quot;/service&quot;,method = RequestMethod.GET) public void acceptWxValid(@RequestParam String signature, @RequestParam String timestamp, @RequestParam String nonce, @RequestParam String echostr, HttpServletResponse response) throws IOException &#123; PrintWriter out = response.getWriter(); if (SignUtil.checkSignature(signature, timestamp, nonce)) &#123; out.print(echostr); &#125;else out.print(&quot;fail&quot;); out.flush(); out.close(); &#125;]]></content>
      <categories>
        <category>随记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与集合(下)]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E9%9B%86%E5%90%88(%E4%B8%8B).html</url>
    <content type="text"><![CDATA[一、Map集合Map类特点:Map类取代了旧的抽象对象Dictionary，拥有更好的性能。没有重复的key，可以有重复的value。Value可以是List、Set、Map类对象。AbstractCollection只实现了remove、clear操作，没有修改和删除KV是否允许有空值，以实现类约束为准。HashMap允许KV都为空，ConcurrentHashMap不允许KV为空二、 树常用的数据机构，它是一个由有限节点组成的一个具有层次关系的集合，数据就存在树的节点中。最顶层只有一个节点成为根节点。结构特点：一个节点，既是只有根节点，也是一棵树。其中任何一个节点与下面所有节点构成的树称为字数。根节点没有父节点，而叶子节点没有子节点。除根节点外，任何节点有且只有一个父节点。任何节点可以有0~n个子节点。最多有两个节点的树称为二叉树，其中最重要的概念是平衡二叉树、二叉查找树、红黑树。1. 平衡二叉树性质：树的左右高度差不能超过1。任何往下递归的左子树与右子树，必须符合第一条性质。没有任何节点的空树或者只有根节点的树也是平衡二叉树。2. 二叉查找树擅长数据查找，对树增加了额外的要求：对于任意节点来说，它的左子树所有节点的值都小于它，而它的右字数所有节点都必须大于它。常见的遍历方式有三种：前序遍历、中序遍历、后续遍历。它们三者规律如下：在任何递归子树中，左节点一定在右节点之前先遍历。前序遍历的顺序是根节点、左节点、右节点；中序遍历的顺序是左节点、根节点、右节点；后序遍历的顺序是左节点、右节点、根节点。3. AVL树一种平衡二叉查找树，增加和删除节点通过树形旋转重新达到平衡。左旋是以某个节点为中心，将它沉入当前左节点的位置，而让当前的右节点成为新树的根节点，也称为逆时针旋转。右旋是以某个节点为中心，将它沉入当前右子节点的位置，而让当前的左节点成为新树的根节点，也称为顺时针旋转。4. 红黑树主要特征是在每个节点上增加一个属性来表示节点的颜色以是红色，也可以是黑色。和AVL树类似，都是在进行插入和删除元素时，通过特定的旋转来保持自首平衡的，从而获得了较高的查找性能。和AVL树相比，红黑树并不追求所有递归子树的高度差不超过1.而是保证从根节点到叶子节点的最长路径不超过最短路径的2倍，通过重新着色和左右旋转，更加高效的完成了插入和删除操作后的自平衡调整。5个约束条件：节点只能是红色或黑色。根节点必须是黑色。所有NIL节点都是黑色的。NIL，即叶子节点下挂的两个虚节点。一条路径上不能出现相邻的两个红色节点。在任何递归子树内，根节点到叶子节点的所有路径上包含相同数目的黑色节点。总结一下：”有红必有黑，红红不相连”。如果一个树的左子节点或者右子节点不存在，则均认定为黑色。红黑树的任何旋转在3次只能均可完成。5. 红黑树和AVL比较:面对频繁插入和删除，红黑树更为合适；面对低频修改、大量查询，AVL树更为合适。三、TreeMap按照Key的排序结果来组织内部结构的Map类集合，它改变了Map类散乱无序的形象。虽然没有ConcurrentHashMap和HashMap普及，但是在Key有排序要求的情况下事半功倍。在继承树中，有两个与众不同的接口：SortedMap和NavigableMap。SortedMap表示它的key是有序不可重复的，支持获得头尾的key-value元素。插入的Key必须实现Comparable接口，所以Key不允许为空，Value可以为空。NavigableMap继承SortedMap接口，根据指定的搜索条件返回最匹配的Key-Value元素。不同于HashMap，TreeMap并非一定要重写hashcode和equals方法来达到Key去重的目的。插入新节点，三个前提条件：需要调整的新节点总是红色的。如果插入新节点的父节点是黑色的，无需调整。如果插入新节点的父节点是红色的，因为红黑树规定不能出现相邻的两个红色节点，所以进入循环判断，或重新着色，或左右旋转，最终达到红黑树的五个约束条件，退出条件如下：1while(x != null &amp;&amp; x!= root &amp;&amp; x.parent.color == RED)&#123;...&#125;如果是根节点，则直接退出，设置为黑色即可；如果不是根节点，并且父节点是红色，则一直调整，直到退出循环。TreeMap的插入操作就是按照Key的对比往下遍历，大于比较值节点的往右走，小于比较值节点的往左走,先按照二叉查找树的特性进行操作，无需关心节点颜色与树的平衡，后续会重新着色旋转，保持红黑树的特性。四、HashMap三个存储概念：名称说明table存储所有节点数据的数组slot哈希槽。即table[i]这个位置bucket哈希桶。table[i]上所有元素形成的表或数的集合除了局部方法或绝对线程安全情况下，优先推荐使用ConcurrentHashMap。两者性能相差无几，但后者解决了 高并发下线程安全的问题。HashMap的死链问题以及扩容数据丢失问题是慎用HashMap的两个主要原因。默认容量16，默认负载因子0.75，当到达阈值(容量 * 负载因子)时，进行扩容。每次扩容容量为原来的两倍。发生hash冲突的情况：两节点Key值相同(hash值一定相同)，导致冲突。两节点Key值不同，但是由于hash函数的局限性导致了hash值相同，导致冲突。两节点Key值不同，hash值也不同，但是hash值对 数组长度取模后相同，导致冲突。高并发中，新增对象丢失原因：并发赋值时被覆盖。已遍历区间新增元素会丢失。“新表被覆盖”。迁移丢失。在迁移过程中，有并发时，next被提前设置为null。JDK1.7和1.8中HashMap的区别：JDK1.7中使用的是头插法，1.8中使用的是尾插法。因为JDK1.7中是用单链表进行的纵向延伸，采用头插法能够提高插入的效率，但是也会出现逆序且环形链表死循环的问题。在1.8之后加入了红黑树，采用尾插法，能够避免出现逆序且链表死循环的问题。扩容后数据存储位置计算方式也不一样:1.7直接使用hash值和需要扩容的二进制数进行&amp;(这里就是为什么扩容的时候为啥一定必须是2的多少次幂的原因所在，因为如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞)(hash值 &amp; length-1)。1.8直接用了1.7的运算规律，扩容前位置 + 扩容大小值=JDK1.8的计算方式，只需要判断Hash值的新增参与运算的位是0还是1就直接迅速算出扩容后的存储方式。JDK1.7是数组 + 单链表的数据结构，1.8之后，使用的是数组 + 链表 + 红黑树的数据结构(当链表的深度到达8时，就会自动扩容把链表转换成红黑树的数据结构来把时间复杂度从O(N)变成O(LogN)提高了效率；当阈值小于6时，红黑树转换成链表)。为什么HashMap是线程不安全的？HashMap在并发时出现的问题主要是两方面：put的时候导致的多线程数据不一致两个线程A和B，A先插入key-value到HashMap中，计算出hash桶的索引坐标，获得该桶的链表头节结点，A执行完后B开始执行插入，假设A计算出来的hash桶索引和B计算出的hash桶索引一样，在B插入后，A再次被调度时，执行了旧数据，覆盖了B的插入记录，这样线程B插入的数据就消失了，从而造成数据不一致。resize而引起死循环当两个线程同时检测到元素个数超过了数组大小 x 负载因子，同时会在put()方法中调用resize(),两个线程同时修改一个链表结构会产生一个循环列表(JDK1.7中，会出现resize前后元素顺序倒置的情况)。接下来再想通过get()获取一个元素，就会出现死循环。五、ConcurrentHashMap高并发下其他哈希式集合：HashTable是JDK1.0引入的集合，以全互斥的方式处理并发情况，性能极差。HashMap是JDK1.2引入的，非线程安全，最大的问题是在并发写的情况下，容易出现死链，导致服务不可用。ConcurrentHashMap是JDK1.5引入的线程安全的哈希式集合。ConcurrentHashMap设计理念；JDK1.8之前：采用分段锁的设计理念，相当于HashTable和HashMap的折中版本，把数据分成一段一段进行存储，给每一段分配一把锁，当线程占用锁访问其中一个数据时候，其他端的数据也能被其他线程方法，实现真正的并发访问。优点：写操作的时候可以只对元素所在的Segment进行加锁即可，不会影响到其他的Segment，并发能力大大提高。缺点：Hash过程要比普通的HashMap要长。JDK1.8之后：参考了HashMap，采用了数组 + 链表 + 红黑树的实现方式来设计，内部大量的采用了CAS操作，彻底放弃了Segment转而采用的是Node。更多知识点会在后面专题介绍，尽情期待。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与集合(上)]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E9%9B%86%E5%90%88(%E4%B8%8A).html</url>
    <content type="text"><![CDATA[一、数据结构定义指逻辑意义上数据组织方式及其相应的处理方式数据结构=逻辑结构+存储结构+（在存储结构上的）运算/操作数据结构是指相互之间存在一种或者多种特定关系的数据元素的集合。是组织并存储数据以便能够有效使用的一种专门格式，它用来反映一个数据的内部构成，即同一个数据由那些成分数据构成，以什么方式构成，是什么结构。数据的逻辑结构数据的逻辑结构指数据元素之间的逻辑关系（和实现无关）分类1：线性结构和非线性结构线性结构有且只有一个开始结点和一个终端结点，并且所有的结点都最多只有一个直接前驱和一个直接后驱。线性表就是一个典型的线性结构，它有四个基本特征：集合中必存在唯一的一个“第一元素”；集合中必存在唯一的一个“最后的元素”；除最后元素外，其他数据元素均有唯一的“后继”；除第一元素外，其他数据元素均有唯一的“前驱”。非线性结构：一个结点元素可能对应多个直接前驱和多个直接后驱。常见的有二叉树，图等。分类2：集合结构、线性结构、树状结构、网状结构集合结构该结构的数据元素之间的关系是“同属于一个集合“，别无其他关系三个特征：确定性（集合中的元素必须是确定的）唯一性（集合中的元素互不相同）、无序性（集合中的元素没有前后之分）线性结构数据结构中线性结构指的是数据元素之间存在着“一对一”的线性关系的数据结构树状结构除了一个元素外，每一个数据元素有且只有一个直接前驱元素，但是可以有多个直接的后续元素，特点是数据元素之间是一对多。网状结构每个数据元素之间都可以有多个直接前驱元素，也可以有多个直接后继元素，特点是数据元素之间是多对多的关系。数据的存储结构数据的存储结构主要包括数据元素本身的存储结构以及数据元素之间关系表示，是数据的逻辑结构在计算机中的表示。分类：顺序储存、链式储存、索引储存以及散列储存顺序存储结构把逻辑上相邻的节点存储在物理位置上相邻的存储单元，结点之间的逻辑关系由存储单元的邻接关系来体现优点：是节省存储空间，因为分配给数据的存储单元全用存放结点的数据，结点之间没有占用额外的存储空间。采用这种方法时，可实现对结点的随机存取，即每一个结点对应一个序号，由该序号可以直接计算出来结点的存储地址。缺点：插入和删除需要移动元素，效率较低。链式储存结构数据元素的存储空间对应的不连续的存储空间，每个存储空间节点对应一个需要存储的元素。每个结点是由数据域和指针域组成。元素之间的逻辑关系通过存储节点之间的链接关系反映出来。特点：比顺序存储结构的存储密度要小；逻辑上相邻的节点物理上不必相邻；插入、删除灵活，不需要改变位置，只需要改变指针中的地址；查找结点是链式存储要比顺序存储慢。索引储存结构除了建立存储结点信息外，还建立附加的索引来标识结点的位置散列存储结构根据结点的关键字直接计算出该结点的存储地址一种神奇的存储结构，添加，查询速度快。二、集合常见有Set,Queue，List，Map接口，全部继承Collection接口。List集合线性数据结构的主要表现，通常存在明确的上一个和下一个元素，也UC你在明确的第一个元素和最后一个元素。常见的又ArrayList和LinkedList两个集合类。ArrayList：容量可以改变的非线程安全集合。内部使用数组存储，集合扩容时会创建更大的数组空间，把原有的数组复制到新数组中。优点：能够快速的随机访问缺点: 插入和删除时候速度很慢，需要移动元素。LinkedList:本质是双向链表，和ArrayList相比，插入和删除速度更快，但是随机访问速度慢。这个接口同时有队列和栈的性质，包含3个重要成员：size、first、size。size是双向链表中节点的个数。first和last分别指向第一个和最后 一个节点。优点：可以将零散的内存单元通过附加引用的方式关联起来，形成按链路顺序查找的线性结构，内存利用率较高。Queue集合一种先入先出的数据结构。队列是一种特殊的线性表，它只允许在表的一端进行获取操作，另一端进行插入操作。当队列为空时，称为空队列。由于其本身FIFO的特性和阻塞操作的特点，常常被作为Buffer(数据缓冲区)使用。Map集合以Key-Value键值作为存储元素实现的哈希结构，Key唯一，value可以重复。最早用于存储键值对的Hashtable因为性能瓶颈已经被淘汰，HashMap线程不安全，ConcurrentHashMap是线程安全的，在多线程中，优先使用ConcurrentHashMap。TreeMap是Key有序的Map类集合。Set集合不允许出现重复元素的集合类型。最常用的有HashSet、TreeSet和LinkedHashSet。HashSet是使用HashMap来实现的，只是value固定为一个静态对象，使用Key保证集合元素的唯一性，但是它不能保证集合元素的顺序。TreeSet是使用TreeMap来实现的，底层作为树结构，在添加新元素到集合中时，按照某种比较规则将其插入合适的位置，保证插入后的集合仍然有序。LinkedHashSet继承自HashSet，具有HashSet的优点，内部使用链表维护元素插入的顺序。三、集合初始化ArrayList如果原始容量13，当添加一个元素时，根据程序中的计算方法，得出113的二进制数右移以为后得到的二进制数110，即十进制数6，最终扩容的大小计算结果为：oledCapacitiy + (oldCapacitiy&gt;&gt;1)=13 + 6 = 19。当使用无参数的构造方法时，默认大小为10，也就说第一次add的时候，分配10的容量，每次都调用Array.copyOf方法。当需要把1000个元素放入集合时候，如果我们没有定义容量，将会产生被动扩容和数组复制的额外开销，甚至有可能导致OOM的风险。HashMap默认容量16，负载因子0.75，基于两数乘积来决定什么时候扩容，第一次扩容按着这个2的幂初始化数组大小，以后每次扩容都是2倍，若没有指定初始值，则为9.96。四、数组与集合数组转集合注意是否使用了视图方式直接返回数组中的数据。我们以Arrays.asList()为例，它把数组转换成集合时，不能使用其修改集合的相关方法，它的add/remove/clear方法会抛出UnsupportedOperationException异常。1234567891011121314151617public static void main(String[] args) &#123; String[] strings = new String[3]; strings[0] = &quot;one&quot;; strings[1] = &quot;two&quot;; strings[2] = &quot;three&quot;; List&lt;String&gt; stringList = Arrays.asList(strings); //修改转换后的集合，成功的把第一个元素&quot;one&quot;变&quot;oneList&quot; stringList.set(0,&quot;oneList&quot;); System.out.println(strings[0]); //以下三个方法编译正确，为什么会抛出运行时异常 stringList.add(&quot;four&quot;); stringList.remove(2); stringList.clear(); //因为asList返回的对象是一个Arrays内部类，并不是真正的ArrayList。&#125;正确使用：12345//正确使用 List&lt;String&gt; stringList1 = new ArrayList&lt;&gt;(Arrays.asList(strings)); stringList1.add(&quot;four&quot;); stringList1.remove(2); stringList1.clear();集合转数组12345678910111213141516171819public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(3); list.add(&quot;one&quot;); list.add(&quot;two&quot;); list.add(&quot;three&quot;); //泛型丢失，无法使用String[]接收返回的结果 Object[] array1 = list.toArray(); //数组长度小于元素长度 String[] array2 = new String[2]; list.toArray(array2); System.out.println(Arrays.asList(array2)); //数组长度等于正确长度 String[] array3 = new String[3]; list.toArray(array3); System.out.println(Arrays.asList(array3));&#125;当数组容量等于集合大小时 运行总是最快的，空间消耗也是最少的。由此证明，如果数组初始大小设 不当，不仅会降低性能，还会浪费空间。使用集合的toArray(T[] array) 方法，转换为数组时 注意需要传入类型完全一样的数组并且它的容量大小为list.size();五、集合与泛型List、List、List&lt;?&gt;的区别？List完全没有类型限制和赋值限定，如果天马行空的乱用，迟早会遭遇类型转换错误；List在接收其他泛型赋值时会编译报错;List&lt;?&gt;是一个泛型，在没有赋值之前可以接收任何类型的集合赋值，赋值之后就不能随便添加了。1234567891011121314151617181920212223242526272829public static void main(String[] args) &#123; //第一段：泛型出现之前的集合定义方式 List a1 = new ArrayList(); a1.add(new Object()); a1.add(new Integer(111)); a1.add(new String(&quot;hello a1a1&quot;)); //第二段：把a1引用赋值给a2，注意a2和a1的区别是增加了泛型限制&lt;Object&gt; List&lt;Object&gt; a2 = a1; a2.add(new Object()); a2.add(new Integer(222)); a2.add(new String(&quot;hello a2a2&quot;)); //第三段：把a1引用赋值给a3，注意a3和a1的区别就是增加了泛型&lt;Integer&gt; List&lt;Integer&gt; a3 = a1; a3.add(new Integer(333)); //下面两行出错，不允许加入非Integer的元素加入集合 a3.add(new Object()); a3.add(new String(&quot;hello a3a3&quot;)); //第四段：把a1引用赋值给a4，a1与a4的区别是增加了通配符 List&lt;?&gt; a4 = a1; //运行删除和清楚元素 a1.remove(0); a4.clear(); //编译出错，不允许增加任何元素 a4.add(new Object()); &#125;&lt;? extends T&gt;与&lt;? super T&gt;的区别？&lt;? extends T&gt;是Get First，适用于消费集合元素的场景，称为上界通配符，可以赋值给任何T或者T的子类的集合，上界为T，取出来的类型带有泛型限制，向上转型为T。&lt;? super T&gt;可以赋值给任何T及T父类的集合，下界为T，称为下界通配符。例如选举代表时，你只能往里投票，取票时，根本不知道谁的票，相当于泛型丢失。extends的场景是put功能受限，而super的场景是get功能受限。六、元素比较归并排序：原理图：代码实现：12345678910111213141516171819202122232425262728293031323334353637//两路归并算法，两个排好序的子序列合并为一个子序列 public void merge(int []a,int left,int mid,int right)&#123; int []tmp=new int[a.length];//辅助数组 int p1=left,p2=mid+1,k=left;//p1、p2是检测指针，k是存放指针 while(p1&lt;=mid &amp;&amp; p2&lt;=right)&#123; if(a[p1]&lt;=a[p2]) tmp[k++]=a[p1++]; else tmp[k++]=a[p2++]; &#125; while(p1&lt;=mid) tmp[k++]=a[p1++];//如果第一个序列未检测完，直接将后面所有元素加到合并的序列中 while(p2&lt;=right) tmp[k++]=a[p2++];//同上 //复制回原素组 for (int i = left; i &lt;=right; i++) a[i]=tmp[i]; &#125; public void mergeSort(int [] a,int start,int end)&#123; if(start&lt;end)&#123;//当子序列中只有一个元素时结束递归 int mid=(start+end)/2;//划分子序列 mergeSort(a, start, mid);//对左侧子序列进行递归排序 mergeSort(a, mid+1, end);//对右侧子序列进行递归排序 merge(a, start, mid, end);//合并 &#125; &#125; @Test public void test()&#123; int[] a = &#123; 49, 38, 65, 97, 76, 13, 27, 50 &#125;; mergeSort(a, 0, a.length-1); System.out.println(&quot;排好序的数组：&quot;); for (int e : a) System.out.print(e+&quot; &quot;); &#125;插入排序：代码实现：1234567891011121314151617181920212223242526272829public static void main(String[] args) &#123; int[] arr = &#123;1,4,6,8,2,5,3,7,9&#125;; System.out.println(&quot;数组排序前顺序&quot;); for (int a : arr) &#123; System.out.print(a + &quot; &quot;); &#125; insertSort(arr); System.out.println(&quot;\n数组排序后的顺序&quot;); for (int a : arr) &#123; System.out.print(a + &quot; &quot;); &#125;&#125;/** * 直接插入排序 * @param arr */private static void insertSort(int[] arr)&#123; for (int i = 1; i &lt; arr.length; i++) &#123; //必须i = 1，因为开始从第二个数与第一个数进行比较 int temp = arr[i]; //待比较值 int j = i - 1; //内存循环为待比较值确定其最终位置 for (;j &gt;= 0 &amp;&amp; arr[j] &gt; temp;j--)&#123;//如果待比较值比前一位值小，应该往前插一位 //将大于temp的值整体后移一位 arr[j+1] = arr[j]; &#125; arr[j+1] = temp;//待比较值值比前一位值大，确定最终位置 &#125;&#125;TimSort：结合归并排序和插入排序的优点，相对于传统归并排序，减少了并归次数，相对于插入排序，引入了二分排序概念，提升排序效率。它主要有两个优化：归并排序的分段不再从单个元素开始，而是每次先查找当前最大的排序好的组数片段run，然后对run进行拓展并进利用二分排序，之后将该run与其他已经排好的run进行归并，产生排好序的大run。引入二分排序，即binarySort。二分排序是对插入排序的优化，在排序中不再是从后往前逐个排序，而是引入了二分查找的思想，将一次查找新元素合适位置的时间复杂度从O(n)降低到O(logn)。hashCode和equals用来标识对象。两个方法协同工作可以用来判断对象是否相等。对象通过Object.hashCode()生成哈希值，由于不可避免地存在哈希值冲突的情况，因此当hashCode相同时，还需要再调用equals进行一次值的比较。如果hashCode不同，直接返回Obejcts不同，跳过equals，加快冲突处理效率，Object定义要求如下：如果两个对象的equals值相等，则两个对象的hashCode的返回结果也一定相等。任何时候重写equals，都必须要重写hashCode。1234567891011121314151617181920212223242526272829303132333435public class Client &#123; private int id; private String name; public Client(int id, String name) &#123; this.id = id; this.name = name; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Client client = (Client) o; return id == client.id &amp;&amp; Objects.equals(name, client.name); &#125; @Override public int hashCode() &#123; return Objects.hash(id, name); &#125; public static void main(String[] args) &#123; Set&lt;Client&gt; hashSet = new HashSet&lt;&gt;(); Client a = new Client(1,&quot;one&quot;); Client b = new Client(1,&quot;one&quot;); Client c = new Client(1,&quot;one&quot;); hashSet.add(a); hashSet.add(b); hashSet.add(c); System.out.println(hashSet.size()); &#125;&#125;七、fail-fast机制集合常见的错误检查机制，通常出现在遍历集合元素的过程中。在遍历途中出现意料之外的修改时，通过unchecked异常暴力反馈出来，这种机制常常出现在多线程环境下，当前线程会维护一个计数比较器，即expectedModCount，记录已经修改的次数。在进入遍历前，会把实时修改次数modCount赋值给expectedModCount，如果两个数据不相等，则抛出异常。java.util下所有的集合包都是fail-fast。123456789101112131415161718192021222324252627282930public static void main(String[] args) &#123; List masterList = new ArrayList(); masterList.add(&quot;one&quot;); masterList.add(&quot;two&quot;); masterList.add(&quot;three&quot;); masterList.add(&quot;four&quot;); masterList.add(&quot;five&quot;); List branchList = masterList.subList(0,3); //下面三行代码如果不注释掉，会导致branchList操作出现异常 masterList.remove(0); masterList.add(&quot;ten&quot;); masterList.clear(); //下面四行全部能执行 branchList.clear(); branchList.add(&quot;sex&quot;); branchList.add(&quot;seven&quot;); branchList.remove(0); //正常遍历，只有一个元素：seven for (Object o: branchList) &#123; System.out.println(o); &#125; //子列表修改导致主列表页被改动，输出：seven，four，five System.out.println(masterList); &#125;concurrent包中所有的集合类都是fail-safe，是在安全的副本上进行遍历，集合修改与副本遍历没有任何关系，但是缺点很明显，就是读取不到最新的数据。Copy-On-Write它是并发的一种新思路，实行读写分离，如果是写操作，则复制一个新集合，在新集合内添加或删除元素。待一切修改完成后，再将原集合的引用指向新的集合，这样做的好处是可以高并发地对COW进行读和遍历操作，而不需要加锁，因为当前集合不会添加任何元素。使用COW时应该注意两点：尽量设置合理的容量初始值，它扩容的代价比较大使用批量添加或者删除方法，如addAll或removeAll操作，在高并发请求下，可以攒一下要添加或者删除的元素，避免增加一个元素复制整个集合。如果集合数据是100MB，再写入50MB，那么某个时间段内占用的内存就达到了（100MB x 2) + 50MB = 250MB,内存大量占用会导致GC的频繁发生，从而降低服务器性能。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常和日志]]></title>
    <url>%2F%E5%BC%82%E5%B8%B8%E5%92%8C%E6%97%A5%E5%BF%97.html</url>
    <content type="text"><![CDATA[一、异常分类JDK中定义了一套完整的异常机制，所有异常都是Throwable的子类，主要有分类如下：Error(致命异常)一种非常特殊的异常，它的出现标识着系统发生了不可控制的错误，例如StackOverflowErro、OutOfMemoryErro。针对这种错误，程序无法处理，只能人工介入。Exception(非致命异常)checked异常(受检异常)需要在代码中显示处理的异常，否则会编译出错。如果能自行处理可以在当前方法中捕获异常，如果无法处理，则继续向调用方法抛出异常，常见的异常主要有SQLException、ClassNotFoundException等。unchecked异常(运行时异常)，他们都继承自RuntimeException，不需要程序进行显式的捕捉和处理。进一步可细分3类：可预测异常,常见的包括IndexOutOfBoundsException，NullPointerException等，基于代码性能和稳定性要求，应该做出提前边界检查，空指针判断等处理。需捕获异常,例如在使用Dubbo框架进行RPC调用时产生的远程服务器超时异常DubboTimeoutException，此类异常客户端必须显示处理，可以是重试或者降级处理。可透出异常，主要是框架或系统产生会自行处理的异常，程序无需关系，比如调转404页面。二、异常处理try代码块，例：123456789pub ic static int finallyNotWork () &#123; int temp = 10000 ; try &#123; throw new Excepti on (); &#125; catch (Exception e ) &#123; return ++temp ;&#125; finally&#123; temp = 99999； &#125;如果没有进入进入finally代码块执行，那么有三种可能：没有进入try代码块。进入try代码块，但是出现了死循环或者死锁。进入try代码块，但是执行了System.exit()操作。注意：finally是在return表达式运行后执行的，此时将要return的结果暂时被保存起来，待finally代码块执行结束后再将之前保存的结果返回，切勿在finally中执行赋值操作。自定义异常，继承Exception或者是RuntimeException，在业务中使用throw new XxxException（“xxx错误”）来使用。例如：123456public class XxxException extends RuntimeException&#123;public XxxException()&#123;&#125;public XxxException(String msg) &#123; super(msg);&#125; &#125;三、日志日志级别：DEBUG级别：记录对调试程序有帮助的信息。INFO级别：用来记录程序运行现场，虽然此处并未发生错误，但是对排查其他错误具有指导意义。WARN级别：也可以用来记录程序运行现场，但是更偏向于表明此处有出现潜在错误的可能。ERROR级别：表明当前程序运行发生了错误，需要被关注。但是当前发生的错误，没有影响系统的继续运行。FATAL级别：表明当前程序运行出现了严重的错误事件，并且将会导致应用程序中断。常见用法：~／／使明条件判断形式if (logger.isDebugEnabled()) {logger.debug (“Erocessing trade with id:”+ id + “and symlbol :” + symbol) ;／／使用占位符形式logger.debug (“Processing trade with id: {} and symbol：{}”,id,symbol);]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[走进JVM]]></title>
    <url>%2F%E8%B5%B0%E8%BF%9BJVM.html</url>
    <content type="text"><![CDATA[一、字节码源码转化成字节码过程：Java源文件-&gt;词法解析-&gt;语法解析-&gt;语义分析-&gt;生成字节码二、类加载过程Java的类加载器是一个运行时核心基础设施模块，主要是在启动之初进行类的Load、Link和Init，即加载、链接、初始化。第一步，Load阶段读取类文件产生二进制流，并转化为特定的数据结构，初步校验cafe babe魔法数、常量池、文件长度、是否有父类，然后创建对应类的java.lang.Class实例。第二步，Link阶段包括验证、准备解析三个步骤。验证是更详细的校验，比如final是否合规、类型是否准确静态变量是否合理、准备阶段是为静态变量分配内存，并设定默认值，解析类和方法确保类与类之间的项目引用准确性，完成内存结构布局。Init阶段执行类构造器方法，如果赋值与那算是通过其他类的静态方法来完成的，那么会马上解析另外一个类，在虚拟机栈中执行完毕后通过返回值进行赋值。三、自定义加载器与双亲委派模型什么是双亲委派模型？如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有的那个父加载类在自己的搜索范围内找不到指定的类时，自加载器才会尝试自己去加载。自定义类加载器loadClass默认实现如下：123public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125;再看看loadClass(String name, boolean resolve)函数：12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125;从上面面代码可以明显看出，loadClass(String,boolean)函数即是实现了双亲委派模型，大致过程如下：首先、检查一下指定名称的类是否已经加载过了，如果加载过了，就不需要加载，直接返回。如果此类没有加载过，那么，再判断下是否有父加载器；如果有，则由父加载器加载，或者调用bootstrap类加载器加载。如果父加载器及bootstrap类加载器都没有找到指定的类，则调用当前类findClass方法来完成类加载。换句话说，如果要自定义类加载器，就必要要重写findClas方法。默认实现如下：123protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException&#123; throw new ClassNotFoundException(name);&#125;若果是读取一个指定的名称的类为字节数组，则使用defineClass转换成Class对象，默认实现如下：1234protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len) throws ClassFormatError &#123; return defineClass(name, b, off, len, null);&#125;函数调用过程：开始-&gt;loadClass-&gt;父类加载器是否返回Class对象？是的话直接返回，否-&gt;findClass-&gt;根据名称读取文件存入字节数组-&gt;defineClas-&gt;返回Clas对象。四、内存布局主要有类加载子系统、java栈、方法区、Java堆、直接内存、本地方法栈、垃圾回收机制、PC寄存器、执行引擎。类加载系统和方法区：类加载系统负责从文件系统或者网络中加载class信息，加载的类信息存放在一块称为方法区的内存空间。除了类的信息外，方法区还有可能存放运行时常量池信息，包括字符串常量和数字常量（这部分常量信息是class文件中常量池部分的内存映射）。Java堆：Java堆在虚拟机启动的时候建立，它是Java程序中最重要的内存工作区域。几乎所有的java对象实例都存放在java堆中。堆空间的所有线程是共享的，这是一块与java应用密切相关的内存空间。直接内存：java的NIO库允许java程序使用直接内存。直接内存是java堆外的，直接向系统申请的工作空间。通常访问直接内存的速度会优于java堆。因此出于性能的考虑，读写频繁的场合可能会考虑使用直接内存。由于直接内存在java堆外，因此它的大小不会受限于xmx指定的最大堆大小，但是系统内存是有限的，java堆和直接内存的总和依然受限于操作系统能给出的最大内存。垃圾回收系统：垃圾回收系统是Java虚拟机的重要组成部分，垃圾回收器可以对方法区、java堆和直接内存进行回收。其中，java堆是垃圾收集器的工作重点。和C/C++不同，java中所有的对象空间释放都是隐式的，也就是说，java中没有类似free()或者delete()这样的函数释放指定的内存区域。对于不再使用的垃圾对象，垃圾回收系统会在后台默默工作，默默的查找，标识并释放垃圾对象，完成包括java堆，直接内存和方法区中全自动化管理。Java栈：每一个java虚拟机线程都有一个私有的java栈，一个线程的java栈在线程创建的时候被创建，java栈中保存着帧的信息，java栈中保存着局部变量、方法参数、同时和java方法的调用、返回密切相关。本地方法栈：本地方法栈和java栈非常类似，最大的不同在于java栈用于方法的调用，而本地方法栈则用于本地方法的调用，作为对java虚拟机的重要拓展，java虚拟机允许java直接调用本地方法（通常使用C编写）。PC寄存器：PC寄存器也是每一个线程私有的空间，java虚拟机会为每一个java线程创建PC寄存器。在任意时刻，一个Java线程总是在执行一个方法，这个正在执行的方法称为当前方法。如果当前方法不是本地方法，PC寄存器就会指向正在被执行的指令。如果当前方法是本地方法，那么PC寄存器的值就是undefined。执行引擎：执行引擎是Java虚拟机的最核心组件之一，它负责执行虚拟机的字节码文件，现代虚拟机为了提高执行效率，会使用即时编译技术将方法编译成机器码后执行。五、垃圾回收分代策略JVM内存分代策略Java虚拟机根据对象存活的周期不同，把堆内存划分为几块，一般分为新生代、老年代和永久代（对HotSpot虚拟机而言），这就是JVM内存分代策略。为什么要分代？堆内存是虚拟机管理的内存中最大的一块，也是垃圾回收机制最频繁的一块区域，我们程序所有的对象实例都存放在堆内存中，给堆内存分代是为了提高对象内存分配和垃圾回收的效率。试想一下，如果堆内存没有区域划分，所有的新创建的对象和生命周期很长的对象放在一起，随着程序的执行，堆内存需要频繁进行垃圾回收，而每次回收都要遍历所有对象，遍历这些对象所花费的时间代价是巨大的，会严重我们的GC效率，这简直太可怕了。有了内存分代，情况就不同了，新创建的对象会在新生代中分配内存，经历过多次回收任然存活下来的对象存放在老年代中，静态属性，类信息存放在永久代中，新生代中的对象存活时间短，只需要在新生代区域中频繁进行GC，老年代中对象生命周期长，内存回收的频率相对较低，不需要频繁进行回收，永久代中回收的效果太差，一般不进行垃圾回收，还可以根据不同年代的特点采用合适的垃圾回收算法。分代收集大大提升了收集效率，这些都是内存分代带来的好处。内存分代划分Java虚拟机将堆内存划分为新生代、老年代和永久代，永久代是HotSpot虚拟机特有的概念，它采用永久代的方式来实现方法区，其他的虚拟机实现没有这一个概念，而且HotSpot也有取消永久代的趋势，在JDK1.7中HotSpot已经开始去“永久化”，把原本放在永久代的字符串常量池移出。永久代主要存放常量、类信息、静态变量等数据，与垃圾回收关系不大，新生代和老年代是垃圾回收的主要区域。新生代新生成的对象优先存放在新生代中，新生代对象朝生夕死，存活率很低，在新生代中，常规应用进行一次垃圾收集一般可以回收70%~95%的空间，回收效率很高。HoSpot将新生代划分为三块，一块较大的Eden空间和两块较小的Survivor空间，默认比例是8：1：1。划分的目的是因为HotSpot采用主从复制算法来回收新生代，设计这个比例是为了充分利用内存空间，减少浪费。新生成的对象在Eden区分配（大对象除外，大对象直接进入老年代），当Eden区没有足够的空间进行分配时，虚拟机将发起一次Minor GC。GC开始时，对象只会存在于Eden区和From Survivor区，To Survivor区是空的（作为保留区）。GC进行时，Eden区所有存活的对象都会被复制到To Survivor区，而在From Survivor区中，任然存活的对象会根据它们的年龄值决定去向，年龄值达到年龄阀值（默认是15，新生代中的对象每熬过一次垃圾回收，年龄值就加一，GC分代年龄储存在对象的header中）的对象就会被移到老年区，没有达到阀值的对象都在To Survivor区。接着清空Eden区和From Survivor区，新生代中存活的对象都在To Survivor区，接着From Survivor区和To Survivor区会交换他们的角色，不管怎样都会保证To Survivor区在一轮GC后是空的。GC时当To Survivor区没有足够的空间存放上一次新生代收集下来的存活对象，需要依赖老年代进行分配担，将这些对象放在老年代区。老年代在新生代中经历了多次GC后任然存活下来的对象会进入老年代中。老年代中的对象生命周期较长，在老年代中进行GC的频率相对而言较低，而且回收的速度较慢。永久代永久代存储类信息、常量、静态变量、即时编译器编译之后的代码等数据，对这一区域而言，Java虚拟机规范指出可以不进行垃圾回收收集，一般而言不会进行垃圾回收。回收算法引用计数法比较古老的算法，原理是此对象有一个引用，既增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象，此算法最致命的是无法处理循环引用的问题。复制*此算法把内存空间分配成两个相等的区域，每次只使用其中的一个区域。垃圾回收时，遍历当前的使用区域，把正在使用的对象复制在另一个区域中，算法每次只处理正在使用中的对象，因此复制都成本较小，同时复制过去还能进行相应的内存整理，不会出现“碎片”问题，当然，此算法的缺点也是很明显的，就是需要两倍的内存空间。标记-清除此算法执行分两阶段，第一阶段从引用根节点开始标记所有被引用的对象，第二阶段遍历整个堆，把未标记的对象清除。此算法需要暂停整个应用，同时，会产生内存碎片。标记-整理此算法整合了“标记-清除”和“复制”两个算法的优点，也是分两个阶段，第一个阶段从根节点开始标记所有被引用的对象，第二个阶段遍历整个堆，清除未标记的对象并且把存活的对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了”复制“算法的空间问题。垃圾回收器Scavenge GC（次收集）和Full GC的区别（全收集）新生代GC（Scavenge GC）：指发生在新生代的GC，因此新生代的Java对象大多都是朝生夕死，所以Scaveng GC非常频繁，一般回收速度也比较快。当Eden空间不足以为对象分配内存时，会触发Scavenge GC。老年代GC（Full GC/Major GC）：Full GC指发生在老年代的GC，出现了Full GC一般都伴随着至少一次的Minor GC（老年代的对象大部分是Minor GC过程中从新生代进入老年代），比如：分配担保失败，Full GC的速度一般会比Minor GC慢10倍以上。当老年代内存不足或者显式调用System.gc()方法时，会触发Full GC。次收集当年轻的空间紧张时会被触发相对于全收集来说，收集间隔较短全收集当老年代或者持久代堆空间满了，会触发全收集操作可以使用System.gc()方法来显式的启动全收集全收集一般根据堆大小的不同，需要的时间不尽相同，但是一般会比较长，不过，如果全收集时间超过了3到5秒钟，那就太长了。新生代收集器串行收集器（Serial）Serial收集器HotSpot运行在client模式下默认的新生代收集器，它的特点是只有一个cpu/一条收集线程去完成GC工作，且在进行垃圾收集时必须暂停其它所有的工作线程。新生代采用复制算法，老年代采用标记-整理算法。并行收集器（ParNew）ParNew是Serial的多线程版本，除了使用多线程进行GC之外，包括Serial可用的所有控制参数、收集算法、STW、对象分配规则、回收策略等都与Serial完全一样，由于存在线程切换的开销，ParNew在单cpu的环境中比不上Serial，但是随着线程的增加，效率会大大增加。新生代采用复制算法，老年代采用标记-整理算法。Parallel Scavenge收集器与ParNew类似，也是使用复制算法，也是并行多线程收集器，但与其他收集器关注尽可能缩短垃圾收集时间不同，Parallel Scavenge收集器更关注系统吞吐量。系统吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）。停顿时间越短越适用于用户交互的程序，而高吞吐量则适用于后台运算而不需要太多交互的任务，可以最高效的利用cpu时间，尽快地完成程序的运算任务。老年代收集器erial Old收集器Serial Old是Serial收集器的老年代版本，同样是单线程收集器，使用标记-整理算法。Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和标记-整理算法，吞吐量优先，主要是和Parallel Scavenge在注重吞吐量及cpu资源敏感系统内使用。CMS收集器CMS是一个具有跨时代的收集器，一款真正意义上的并发收集器，虽然已经有了理论意义上表现更好的G1收集器，但现在主流互联网企业线上仍然是CMS。CMS是一种以获取最短回收停顿时间为目标的收集器，又称为多并发低暂停的收集器，基于标记-清除算法实现，整个GC过程分为以下4个步骤：初始标记；并发标记；重新标记；并发清除。由于CMD采用标记-清除算法实现，可能会产生大量的内存碎片，内存碎片过多会导致无法分配大对象而提前触发Full GC，因此CMS提供了-xx：+UseCMSCompactAtFullCollection开关参数。用于在Full GC之后再执行一次碎片整理过程，但是内存整理是无法并发的，内存碎片问题虽然没有了， 但是停顿时间也因此变长了，因此CMS还提供了一个参数-xx：CMSFullGCsBeforeCompaction用于设置在执行N次不进行内存整理的Full GC后，跟着来一次带整理的。分区收集-G1收集器（Garbage-First）G1是一款面向服务端应用的收集器，主要目标用于配备多频cpu的服务器治理大内存–XX:+UseG1GC，启动G1收集与其他基于分代的收集器不同，G1将整个Java堆划分分为多个大小相等的独立区域，虽然还保留着新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java泛型知识点]]></title>
    <url>%2F%E6%B3%9B%E5%9E%8B.html</url>
    <content type="text"><![CDATA[一、什么是泛型？本质就是类型参数化，可以定义在类、接口、方法中，编辑器通过识别尖括号和尖括号内的字母来解析泛型。在定义泛型时，约定俗称的符号包括：E代表Element，用户集合中的元素；T代表the type of object，表示某个类；K代表Key，V代表Value，用户键值对元素。二、使用泛型的好处类型安全。放置的是什么，取回来的自然是什么，不用担心会抛出ClassCastException异常。提升可读性，从编码阶段就显式地知道泛型集合、泛型方法等处理的对象类型是什么。代码重用。泛型合并了同类型的处理代码，使代码重用度变高。三、常见用法泛型类：1234567891011class DateHolder&lt;T&gt;&#123; T item; public void setData(T t)&#123; this.item = t; &#125; public T getDat()&#123; return this.item; &#125;&#125;泛型方法12345678910111213141516171819class DateHolder&lt;T&gt;&#123; T item; public void setData(T t)&#123; this.item = t; &#125; public T getDat()&#123; return this.item; &#125; /** * 泛型方法 * @param e */ public &lt;E&gt; void PrinterInfo(E e)&#123; system.out.println(e); &#125;&#125;泛型接口1234//定义一个泛型接口public interface Generator&lt;T&gt;&#123; public T next();&#125;四、泛型擦除及其相关内容我们下面看一个例子：12345678910Class&lt;?&gt; class1 = new ArrayList&lt;String&gt;().getClass();Class&lt;?&gt; class2 = new ArrayList&lt;Integer&gt;().getClass();System.out.println(class1);System.out.println(class2);System.out.println(class1.equals(class2);结果： java.util.ArrayList java.util.ArrayList true我们看输出发现，class1和class2居然是同一个类型ArrayList，在运行时我们传入的类型变量String和Integer都被丢掉了。Java语言泛型在设计的时候为了兼容原来的旧代码，Java的泛型机制使用了”擦除机制”。注意：编译器虽然会在编译过程中移除参数的类型信息，但是会保证类或方法内部参数类型的一致性。泛型参数将会被擦除到它的第一个边界，如果没有指明边界，那么类型将会被擦除到Object。类型擦除原理：在编译过程中，类型变量的信息是能拿到的。所以，set方法在编辑器可以做类型检查，非法类型不能通过编译。但是对于get方法，由于擦除机制，运行时的实际引用为Object类型，为了还原返回结果的类型，编辑器在get方法后面添加了类型转换。类型擦除的缺陷和补救措施泛型类型不能显示地运用在运行时类型的操作中，例如：转型、instanceof 和 new。因为在运行中，所有参数的类型都丢失了。类似如下代码则无法通过编译：1234567891011121314public class Erased&lt;T&gt;&#123; private final int SIZE = 100; public static void f(Object arg)&#123; //编译不通过 if(arg instanceof T)&#123; &#125; //编译不通过 T var = new T(); //编译不通过 T[] array = new T[SIZE]; //编译不通过 T[] array = (T) new Object[SIZE]; &#125;&#125;解决措施：类型判断问题123456789101112131415/** * 泛型类型判断封装类 * */class GenericType&lt;T&gt;&#123; Class&lt;?&gt; classType; public GenericType(Class&lt;?&gt; type)&#123; this.classType = type; &#125; public boolean isInstance(Object object)&#123; return classType.inInstance(Object); &#125;&#125;创建类型实例123456789101112131415161718192021222324/** *使用工厂方法来创建实例 * * */interface Factory&lt;T&gt;&#123; T create();&#125;class creater&lt;T&gt;&#123; T instance; public &lt;F extends Factory&lt;T&gt;&gt;T newInstance(F f)&#123; instance = f.create(); return instance; &#125;&#125;class IntegerFactory implements Factory&lt;Integer&gt;&#123; @Override public Integer create()&#123; Integer integer = new Integer(9); return integer &#125;&#125;创建泛型数组一般不建议创建泛型数组，尽量使用ArrayList来代替泛型数组。五、Java泛型的通配符上界通配符&lt;? extends T&gt;:只适合频繁读取的场景，例：1234class Food&#123;&#125;class Fruit extends Food&#123;&#125;class Apple extends Fruit&#123;&#125;class Banana extends Fruit&#123;&#125;在上面这个层次，可以用Plate&lt;? extends Fruit&gt;,无法存放，因为编译器只知道容器里存放的是Fruit和它的派生类，不知道具体类，但是可以进行读取操作。下界通配符&lt;? super T&gt;:不影响往里面存储，但是读取出来的数据只能是Object类型，里面存储的都是T及其基类，无法转换成任何一种类型，只能转换成Object基类才能放下。&lt;?&gt;无限通配符无界通配符修饰的容器持有的是某种具体的类型。举个例子，在List&lt;？&gt;类型的引用中，不能向其中添加Object，而在List类型的引用中，可以添加Object对象。PECS原则：上界&lt;? extends T&gt;不能往里存，只能往外取，适合频繁往外面读取内容的场景。下界&lt;? super T&gt;不影响往里存，但往外取只能放在Object对象里，适合经常往里面插入数据的场景。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP/HTTPS]]></title>
    <url>%2Fhttp%E5%92%8Chttps.html</url>
    <content type="text"><![CDATA[一、什么是HTTP和HTTPS？HTTP：超文本传输协议，所有的www文件都必须遵守这个标准，互联网上应用最广泛的一种网络协议。HTTPS:是以安全为目标的HTTP通道，简单来说就是HTTP的安全办，即HTTP下加入SLL层，HTTPS的安全基础是SLL，因此加密的详细内容就需要要SSL。主要作用：建立一个信息安全通道，保证数据安全；确定网站真实性。二、两者区别http免费试用，https协议需要ca申请证书，一般免费证书很少，需要交费。http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。http和https使用的完全不一样的端口，前者是80，后者是443。http的连接很简单，是无状态的。https协议是由ssl+http协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。三、HTTPS工作流程客户端使用https的URL访问Web服务器，要求与Web服务器建立SSL连接；Web服务器接收客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端；客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级；客户端浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站；Web服务器利用自己的私钥解密会话密钥；Web服务器利用会话密钥加密与客户端之间的通信。四、一句话总结HTTPSHTTPS要使客户端与服务器端的通信过程得到安全的保证。必须使用对称加密，但是协商对称密钥的过程，需要使用非对称加密算法来保证安全，然而直接使用非对称加密的过程本身就不安全，会有中间人篡改公钥的可能性，所以客户端与服务器不直接使用公钥，而是使用数字证书签发机构颁发的证书来保证非对称加密过程本身的安全。这样通过这种机制协商出一个对称加密算法，之后双方再使用该算法进行加解密，从而解决了客户端与服务端之间的通信安全问题。五、常见问题TLS和SLL的区别？TLS可以理解成SSL协议3.0版本的升级，所以TLS的1.0版本也被标识为SSL3.1版本。什么是对称加密和非对称加密？对称加密：最快速、最简单的加密方式，加密与解密同样的密钥，这种方法在密码学中叫做对称加密算法。最大缺点是密钥的管理和分配，在发送密钥的过程中，密钥有很大的风险会被黑客拦截。通常做法是将对称加密的密钥进行非对称加密，然后传输给需要他的人。非对称加密：为数据加密与解密提供了一个非常安全的方法，它使用了一对密钥，公钥和私钥。私钥只能由一方保管，不能外泄，而公钥则可以发送给任何请求它的人。非对称加密使用这对密钥中的一个进行加密，而解密则需要另一个密钥。比如，你向银行请求公钥，银行将公钥发送给你，你使用公钥对数据加密，只有私钥的持有人银行才能对你的消息进行解密，安全性大大提高。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络安全]]></title>
    <url>%2F%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8.html</url>
    <content type="text"><![CDATA[一、黑客与安全黑客：攻击手段分为非破坏性攻击和破坏性攻击。非破坏型攻击：一般是为了扰乱系统的运行，使之暂时失去对外提供服务的能力，比如DDos攻击。破坏性攻击：主要会造成两种后果:系统数据收送或者信息被窃取，比如CSRF攻击。攻击手段有病毒式、洪水式、系统漏洞式。安全：互联网企业都要建立一套完整的信息安全体系，遵循CIA原则，即保密性、完整性、可用性。保密性：对需要保护的数据（例如用户的私人信息等）进行保密操作，无论是存储还是传输，都要保证用户数据及相关资源的安全。完整性：访问的数据需要是完整的，而不是缺失或者篡改的，必然用户访问的数据就是不正确的。可用性：服务必须是可用的。二、SQL注入SQL注入是注入式攻击中常见的类型，是未将代码与数据进行严格的隔离，导致在读取用户数据时候，错误的把数据作为代码的一部分执行，从而导致安全问题。常见案例：123var testCondition;testCondition = Request.from(&quot;testCondition&quot;)var sql = &quot;select * from TableA where id =&apos;&quot;+ testCondition +&quot;&apos;&quot;;上面例子，若果用户只输入ID是一个数字是没有问题的，但是如果用”;”隔开，在testCondition中插入其他SQL，则会带来意想不到的结果。如何预防？过滤用户输入参数中的特殊字符，从而降低被SQL注入的风险；禁止通过字符串凭借的SQL语句，严格使用参数绑定传入的SQL参数；合理使用数据库访问框架提供的防注入机制。例如Mybatis提供的#{} 绑定数据，从而防止SQL注入。同时谨慎使用${},${}相当于使用字符串拼接SQL，拒绝拼接的SQL语句，使用参数化的语句。三、XSS与CSRFXSS:跨站脚本攻击，指黑客通过技术手段，向正常用户请求的HTML页面中插入恶意的脚本，从而可以执行任意脚本,比如如下代码可能造成XSS漏洞12345&lt;div&gt;&lt;h3&gt;反射型xss示例&lt;h3&gt;&lt;br&gt;用户：&lt;%= request.getParameter(&quot;userName&quot;) %&gt;&lt;br&gt;系统错误信息：&lt;%= request.getParameter(&quot;errorMessage&quot;) %&gt;&lt;/div&gt;上面的代码从HTTP请求中获取了userName和errorMessage两个参数，并直接输出到HTML中展示，当黑客构造如下的URL时出现了反射型XSS1http://xss.demo/self-xss.jsp?userName= 张三&lt;script&gt;alert(&quot;张三&quot;)&lt;/script&gt;&amp;errorMessage=XSS示例&lt;script src=http://hacker.demo/xss-script.js /&gt;防范措施：使用Jsonp框架对用户输入字符串做XSS过滤；使用框架的工具类对用户输入的字符串做HTML转义，例如Spring提供的HtmlUtils；前端展示数据时使用innerText而不是innerHTML。CSRF：跨站请求伪造，在用户不知情的情况下，冒用用户发起请求，在当前已经登录的Web应用上执行恶意操作，如恶意发帖，修改密码等。比如某用户A登录了网上银行，这时黑客给他发了一条连接如下：1https//net_bank.demo/transfer.do?targetAccount=12345&amp;amount=100如果用户在打开网银的浏览器中点开了黑客发送的URL,那么就有可能给黑客转账100元。防范措施：CSRF Token验证，利用浏览器的同源限制，在HTTP接口执行前验证页面或者Cookie中设置的Token，只有验证通过才能继续执行请求；人机交互，比如在调用网上银行转账时校验短信验证码。四、两者差别XSS是在正常用户请求的HTML页面中执行了黑客提供的恶意代码；CSRF是黑客直接盗用浏览器中的登录信息，冒充用户去执行黑客指定的操作。XSS问题出在用户数据没有过滤、转义；CSRF问题出现在HTTP接口没有防范不受信任的调用。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是TCP/IP]]></title>
    <url>%2FTCP-IP.html</url>
    <content type="text"><![CDATA[一、网络协议TCP/IP :中文翻译为传输控制协议，通常有4层协议：应用层、传输层、网络层、链路层。链路层：主要有IEEE 802.x/PPP 等，以字节为单位把0与1进行分组，定义数据帧，写入源和目标机器的物理地址、数据、校验位来传输数据。网络层：主要有IP/APR等，根据IP定义网络地址，区分网段。子网内根据地址解析协议（ARP）进行MAC寻址，子网外进行路由转发数据包，这个数据包即为IP数据包。传输层：主要有TPC/UDP等，数据包通过网络层发送到目标计算机后，应用程序在传输层定义逻辑端口，确认身份，把数据包交给应用程序，实现端口与端口间的通信。应用层：主要有HTTP/FTP/SMTP等，传输层的数据到达应用程序后，以某种统一规定的协议格式解读数据。二、IP协议IP协议是面向无连接、无状态、没有额外的机制保证发送的包是否有序到达。是TCP/IP的基石，几乎所有其他协议都是建立在IP所提供的服务基础上进行传输，其中包括在实际应用中用于传输稳定有序数据的TCP。三、TPC建立链接传输控制协议。是一种面向连接、确保数据在端与端之间可靠传输的协议。三次握手:A机器发出一个数据包并将SYN置1，表示希望建立连接；B机器收到A机器发过来的数据包，通过SYN得知这是一个建立连接的请求，于是发送一个响应包并将SYN和ACK标记都置为1。假设这个包中的序列号是y，而确认序列号必须是x+1，表示收到了A发过来的SYN，在TCP中，SYN被当做数据部分的一个字节；A收到B的响应包后进行确认，确认包中将ACK置为1，并将确认序列号置为y+1，表示收到来自B的SYN。目的： 信息对等，防止超时。四、TCP断开连接四次挥手：A机器想要关闭连接，则待本方数据发送完毕之后，传递FIN信号给B机器；B机器应答ACK，告诉A机器可以断开，但是要等B机器处理完数据，再主动给A机器发送FIN信号，此时A机器处于半关闭状态，无法发送新的数据；B机器做好链接关闭的准备后，发送FIN信号给A机器，此时B机器也进入半关闭状态；A机器发送针对B机器FIN的ACK后，进入TIME-WAIT状态，经过2MSL后，没有收到B发送的报文，则确定B机器已经收到A机器最后发送的ACK命令，此时TCP正式释放。五、常见问题1. TCP和UDP区别？TCP:面向连接点到点通信高可靠性占用系统资源多、效率低利用IO流实现数据的传输响应式请求UDP:非面向连接，传输不可靠，可能丢失发送不管对方是否准备好，接受到也不确认可以广播发送非常简单的协议，开销小效率高，不用IO流实现数据的传输2. 为什么连接的时候是三次握手，断开的时候是四次挥手？当服务端收到客户端的连接请求报文时，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的，但是关闭连接时候，当服务端收到FIN报文时，不会立刻关闭SOCKET，只能先回复一个ACK报文，告诉客户端你的FIN报文收到了，只有等我服务端所有的报文发送完，我才能发送FIN报文，因此不能一次发送，需要四步。3.为什么不用两次握手链接？容易发生死锁，客户端在服务端的应答分组在传输中被丢失的情况下，将不知道服务端是否准备好，不知道服务端建立什么样的序列号，在这种情况下，客户端认为链接还未建立，将忽略服务端发来的任何数据分组，只能等待链接确认才应答f分组，而服务端发出的分组超时后，重复发送同样的分组，这样就行成了死锁。4.为什么TIME-WAIT状态需要经过2MSL才能返回到Close状态？按照道理来说，四个报文发送完毕，我们可以直接进入CLOSE状态，但是我们假象网络是不可靠的，有可能最后一个ACK丢失，所以TIME-WAIT状态是用来重发可能丢失的ACK报文。在客户端发送出最后的ACK回复，但该ACK可能丢失，服务端如果没有收到ACK，则不断的发送FIN片段，所以客户端不能立即关闭，它必须确认客户端收到了该ACK，此时设置了一个定时器，如果直到2MSL，客户端都没有收到FIN，则推断ACK已经成功被接收，关闭连接。5.如果已经建立了连接，但是客户端突然出现故障怎么办？TPC设有一个保活计时器，服务端每次接收到请求都会重新复位这个计时器，时间通常是2小时，若2小时没有收到客户端的任何数据，则服务端会发送一个探测报文段，以后每隔75秒发送一次，若一连发送10个探测报文都没有反应，则认为客户端发生故障，关闭连接。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>socket</tag>
      </tags>
  </entry>
</search>
